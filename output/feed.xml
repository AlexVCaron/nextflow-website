<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nextflow Blog</title>
    <link>http://www.nextflow.io/</link>
    <atom:link href="http://www.nextflow.io//feed.xml" rel="self" type="application/rss+xml" />
    <description>Blogging about Nextflow, computational pipelines and parallel programming</description>
    <language>en-gb</language>
    <pubDate>Wed, 18 May 2016 11:24:19 +0200</pubDate>
    <lastBuildDate>Wed, 18 May 2016 11:24:19 +0200</lastBuildDate>

    <item>
      <title>Workflows &amp; publishing: best practice for reproducibility </title>
      <link>http://www.nextflow.io//blog/2016/best-practice-for-reproducibility.html</link>
      <pubDate>Wed, 13 Apr 2016 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2016/best-practice-for-reproducibility.html</guid>
      	<description>
	&lt;p&gt;Publication time acts as a snapshot for scientific work. Whether a project is ongoing or not, work which was performed months ago must be described, new software documented, data collated and figures generated. &lt;/p&gt;&lt;p&gt;The monumental increase in data and pipeline complexity has led to this task being performed to many differing standards, or &lt;a href=&quot;http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0080278&quot;&gt;lack of thereof&lt;/a&gt;. We all agree it is not good enough to simply note down the software version number. But what practical measures can be taken?&lt;/p&gt;&lt;p&gt;The recent publication describing &lt;em&gt;Kallisto&lt;/em&gt; &lt;a href=&quot;http://dx.doi.org/10.1038/nbt.3519&quot;&gt;(Bray et al. 2016)&lt;/a&gt; provides an excellent high profile example of the growing efforts to ensure reproducible science in computational biology. The authors provide a GitHub &lt;a href=&quot;https://github.com/pachterlab/kallisto_paper_analysis&quot;&gt;repository&lt;/a&gt; that &lt;em&gt;“contains all the analysis to reproduce the results in the kallisto paper”&lt;/em&gt;. &lt;/p&gt;&lt;p&gt;They should be applauded and indeed - in the Twittersphere - they were. The corresponding author Lior Pachter stated that the publication could be reproduced starting from raw reads in the NCBI Sequence Read Archive through to the results, which marks a fantastic accomplishment.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Hoping people will notice &lt;a href=&quot;https://t.co/qiu3LFozMX&quot;&gt;https://t.co/qiu3LFozMX&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/yarbsalocin&quot;&gt;@yarbsalocin&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hjpimentel&quot;&gt;@hjpimentel&lt;/a&gt; &lt;a href=&quot;https://twitter.com/pmelsted&quot;&gt;@pmelsted&lt;/a&gt; reproducing ALL the &lt;a href=&quot;https://twitter.com/hashtag/kallisto?src=hash&quot;&gt;#kallisto&lt;/a&gt; paper from SRA→results&lt;/p&gt;&amp;mdash; Lior Pachter (@lpachter) &lt;a href=&quot;https://twitter.com/lpachter/status/717279998424457216&quot;&gt;April 5, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;p&gt;They achieve this utilising the workflow framework &lt;a href=&quot;https://bitbucket.org/snakemake/snakemake/wiki/Home&quot;&gt;Snakemake&lt;/a&gt;. Increasingly, we are seeing scientists applying workflow frameworks to their pipelines, which is great to see. There is a learning curve, but I have personally found the payoffs in productivity to be immense.&lt;/p&gt;&lt;p&gt;As both users and developers of Nextflow, we have long discussed best practice to ensure reproducibility of our work. As a community, we are at the beginning of that conversation - there are still many ideas to be aired and details ironed out - nevertheless we wished to provide a &lt;em&gt;state-of-play&lt;/em&gt; as we see it and to describe what is possible with Nextflow in this regard.&lt;/p&gt;&lt;h3&gt;Guaranteed Reproducibility&lt;/h3&gt;&lt;p&gt;This is our goal. It is one thing for a pipeline to be able to be reproduced in your own hands, on your machine, yet is another for this to be guaranteed so that anyone anywhere can reproduce it. What I mean by guaranteed is that when a given pipeline is executed, there is only one result which can be output. Envisage what I term the &lt;em&gt;reproducibility triangle&lt;/em&gt;: consisting of data, code and compute environment.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;/img/reproducibility-triangle.png&quot; alt=&quot;Reproducibility Triangle&quot;&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; The Reproducibility Triangle. &lt;em&gt;Data&lt;/em&gt;: raw data such as sequencing reads, genomes and annotations but also metadata such as experimental design. &lt;em&gt;Code&lt;/em&gt;: scripts, binaries and libraries/dependencies. &lt;em&gt;Environment&lt;/em&gt;: operating system.&lt;/p&gt;&lt;p&gt;If there is any change to one of these then the reproducibililty is no longer guaranteed. For years there have been solutions to each of these individual components. But they have lived a somewhat discrete existence: data in databases such as the SRA and Ensembl, code on GitHub and compute environments in the form of virtual machines. We think that in the future science must embrace solutions that integrate each of these components natively and holistically.&lt;/p&gt;&lt;h3&gt;Implementation&lt;/h3&gt;&lt;p&gt;Nextflow provides a solution to reproduciblility through version control and sandboxing.&lt;/p&gt;&lt;h4&gt;Code&lt;/h4&gt;&lt;p&gt;Version control is provided via &lt;a href=&quot;http://www.nextflow.io/docs/latest/sharing.html&quot;&gt;native integration with GitHub&lt;/a&gt; and other popular code management platforms such as Bitbucket and GitLab. Pipelines can be pulled, executed, developed, collaborated on and shared. For example, the command below will pull a specific version of a &lt;a href=&quot;https://github.com/cbcrg/kallisto-nf&quot;&gt;simple Kallisto + Sleuth pipeline&lt;/a&gt; from GitHub and execute it. The &lt;code&gt;-r&lt;/code&gt; parameter can be used to specify a specific tag, branch or revision that was previously defined in the Git repository. &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow run cbcrg/kallisto-nf -r v0.9
&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;Environment&lt;/h4&gt;&lt;p&gt;Sandboxing during both development and execution is another key concept; version control alone does not ensure that all dependencies nor the compute environment are the same.&lt;/p&gt;&lt;p&gt;A simplified implementation of this places all binaries, dependencies and libraries within the project repository. In Nextflow, any binaries within the the &lt;code&gt;bin&lt;/code&gt; directory of a repository are added to the path. Also, within the Nextflow &lt;a href=&quot;https://github.com/cbcrg/kallisto-nf/blob/master/nextflow.config&quot;&gt;config file&lt;/a&gt;, environmental variables such as &lt;code&gt;PERL5LIB&lt;/code&gt; can be defined so that they are automatically added during the task executions. &lt;/p&gt;&lt;p&gt;This can be taken a step further with containerisation such as &lt;a href=&quot;http://www.nextflow.io/docs/latest/docker.html&quot;&gt;Docker&lt;/a&gt;. We have recently published &lt;a href=&quot;https://doi.org/10.7717/peerj.1273&quot;&gt;work&lt;/a&gt; about this: briefly a &lt;a href=&quot;https://github.com/cbcrg/kallisto-nf/blob/master/Dockerfile&quot;&gt;dockerfile&lt;/a&gt; containing the instructions on how to build the docker image resides inside a repository. This provides a specification for the operating system, software, libraries and dependencies to be run.&lt;/p&gt;&lt;p&gt;The images themself also have content-addressable identifiers in the form of &lt;a href=&quot;https://docs.docker.com/engine/userguide/containers/dockerimages/#image-digests&quot;&gt;digests&lt;/a&gt;, which ensure not a single byte of information, from the operating system through to the libraries pulled from public repos, has been changed. This container digest can be specified in the &lt;a href=&quot;https://github.com/cbcrg/kallisto-nf/blob/master/nextflow.config&quot;&gt;pipeline config file&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;process {
    container = &amp;quot;cbcrg/kallisto-nf@sha256:9f84012739...&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When doing so Nextflow automatically pulls the specified image from the Docker Hub and manages the execution of the pipeline tasks from within the container in a transparent manner, i.e. without having to adapt or modify your code. &lt;/p&gt;&lt;h4&gt;Data&lt;/h4&gt;&lt;p&gt;Data is currently one of the more challenging aspect to address. &lt;em&gt;Small data&lt;/em&gt; can be easily version controlled within git-like repositories. For larger files the &lt;a href=&quot;https://git-lfs.github.com/&quot;&gt;Git Large File Storage&lt;/a&gt;, for which Nextflow provides built-in support, may be one solution. Ultimately though, the real home of scientific data is in publicly available, programatically accessible databases. &lt;/p&gt;&lt;p&gt;Providing out-of-box solutions is difficult given the hugely varying nature of the data and meta-data within these databases. We are currently looking to incorporate the most highly used ones, such as the &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/sra&quot;&gt;SRA&lt;/a&gt; and &lt;a href=&quot;http://www.ensembl.org/index.html&quot;&gt;Ensembl&lt;/a&gt;. In the long term we have an eye on initiatives, such as &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/bioproject/&quot;&gt;NCBI BioProject&lt;/a&gt;, with the idea there is a single identifier for both the data and metadata that can be referenced in a workflow.&lt;/p&gt;&lt;p&gt;Adhering to the practices above, one could imagine one line of code which would appear within a publication. &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow run [user/repo] -r [version] --data[DB_reference:data_reference] -with-docker
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The result would be guaranteed to be reproduced by whoever wished. &lt;/p&gt;&lt;h3&gt;Conclusion&lt;/h3&gt;&lt;p&gt;With this approach the reproducilbility triangle is complete. But it must be noted that this does not guard against conceptial or implemenation errors. It does not replace proper documentation. What it does is to provide transparency to a result.&lt;/p&gt;&lt;p&gt;The assumption that the deterministic nature of computation makes results insusceptible to irreproducbility is clearly false. We consider Nextflow with its other features such its polyglot nature, out-of-the-box portability and native support across HPC and Cloud environments to be an ideal solution in our everyday work. We hope to see more scientists adopt this approach to their workflows. &lt;/p&gt;&lt;p&gt;The recent efforts by the &lt;em&gt;Kallisto&lt;/em&gt; authors highlight the appetite for increasing these standards and we encourage the community at large to move towards ensuring this becomes the normal state of affairs for publishing in science.&lt;/p&gt;&lt;h3&gt;References&lt;/h3&gt;&lt;p&gt;Bray, Nicolas L., Harold Pimentel, Páll Melsted, and Lior Pachter. 2016. “Near-Optimal Probabilistic RNA-Seq Quantification.” Nature Biotechnology, April. Nature Publishing Group. doi:10.1038/nbt.3519.&lt;/p&gt;&lt;p&gt;Di Tommaso P, Palumbo E, Chatzou M, Prieto P, Heuer ML, Notredame C. (2015) &quot;The impact of Docker containers on the performance of genomic pipelines.&quot; PeerJ 3:e1273 doi.org:10.7717/peerj.1273.&lt;/p&gt;&lt;p&gt;Garijo D, Kinnings S, Xie L, Xie L, Zhang Y, Bourne PE, et al. (2013) &quot;Quantifying Reproducibility in Computational Biology: The Case of the Tuberculosis Drugome.&quot; PLoS ONE 8(11): e80278. doi:10.1371/journal.pone.0080278&lt;/p&gt;
	</description>
    </item>
    <item>
      <title>Error recovery and automatic resource management with Nextflow</title>
      <link>http://www.nextflow.io//blog/2016/error-recovery-and-automatic-resources-management.html</link>
      <pubDate>Thu, 11 Feb 2016 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2016/error-recovery-and-automatic-resources-management.html</guid>
      	<description>
	&lt;p&gt;Recently a new feature has been added to Nextflow that allows failing jobs to be rescheduled, automatically increasing the amount of computational resources requested. &lt;/p&gt;&lt;h2&gt;The problem&lt;/h2&gt;&lt;p&gt;Nextflow provides a mechanism that allows tasks to be automatically re-executed when a command terminates with an error exit status. This is useful to handle errors caused by temporary or even permanent failures (i.e. network hiccups, broken disks, etc.) that may happen in a cloud based environment. &lt;/p&gt;&lt;p&gt;However in an HPC cluster these events are very rare. In this scenario error conditions are more likely to be caused by a peak in computing resources, allocated by a job exceeding the original resource requested. This leads to the batch scheduler killing the job which in turn stops the overall pipeline execution. &lt;/p&gt;&lt;p&gt;In this context automatically re-executing the failed task is useless because it would simply replicate the same error condition. A common solution consists of increasing the resource request for the needs of the most consuming job, even though this will result in a suboptimal allocation of most of the jobs that are less resource hungry. &lt;/p&gt;&lt;p&gt;Moreover it is also difficult to predict such upper limit. In most cases the only way to determine it is by using a painful fail-and-retry approach. &lt;/p&gt;&lt;p&gt;Take in consideration, for example, the following Nextflow process: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;process align {
    executor &amp;#39;sge&amp;#39; 
    memory 1.GB 
    errorStrategy &amp;#39;retry&amp;#39; 

    input: 
    file &amp;#39;seq.fa&amp;#39; from sequences 

    script:
    &amp;#39;&amp;#39;&amp;#39;
    t_coffee -in seq.fa 
    &amp;#39;&amp;#39;&amp;#39;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The above definition will execute as many jobs as there are fasta files emitted by the &lt;code&gt;sequences&lt;/code&gt; channel. Since the &lt;code&gt;retry&lt;/code&gt; &lt;em&gt;error strategy&lt;/em&gt; is specified, if the task returns a non-zero error status, Nextflow will reschedule the job execution requesting the same amount of memory and disk storage. In case the error is generated by &lt;code&gt;t_coffee&lt;/code&gt; that it needs more than one GB of memory for a specific alignment, the task will continue to fail, stopping the pipeline execution as a consequence. &lt;/p&gt;&lt;h2&gt;Increase job resources automatically&lt;/h2&gt;&lt;p&gt;A better solution can be implemented with Nextflow which allows resources to be defined in a dynamic manner. By doing this it is possible to increase the memory request when rescheduling a failing task execution. For example: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;process align { 
    executor &amp;#39;sge&amp;#39;
    memory { 1.GB * task.attempt }
    errorStrategy &amp;#39;retry&amp;#39; 

    input: 
    file &amp;#39;seq.fa&amp;#39; from sequences 

    script:
    &amp;#39;&amp;#39;&amp;#39;
    t_coffee -in seq.fa 
    &amp;#39;&amp;#39;&amp;#39;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In the above example the memory requirement is defined by using a dynamic rule. The &lt;code&gt;task.attempt&lt;/code&gt; attribute represents the current task attempt (&lt;code&gt;1&lt;/code&gt; the first time the task is executed, &lt;code&gt;2&lt;/code&gt; the second and so on). &lt;/p&gt;&lt;p&gt;The task will then request one GB of memory. In case of an error it will be rescheduled requesting 2 GB and so on, until it is executed successfully or the limit of times a task can be retried is reached, forcing the termination of the pipeline. &lt;/p&gt;&lt;p&gt;It is also possible to define the &lt;code&gt;errorStrategy&lt;/code&gt; directive in a dynamic manner. This is useful to re-execute failed jobs only if a certain condition is verified. &lt;/p&gt;&lt;p&gt;For example the Univa Grid Engine batch scheduler returns the exit status &lt;code&gt;140&lt;/code&gt; when a job is terminated because it&apos;s using more resources than the ones requested. &lt;/p&gt;&lt;p&gt;By checking this exit status we can reschedule only the jobs that fail by exceeding the resources allocation. This can be done with the following directive declaration: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;errorStrategy { task.exitStatus == 140 ? &amp;#39;retry&amp;#39; : &amp;#39;terminate&amp;#39; }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this way a failed task is rescheduled only when it returns the &lt;code&gt;140&lt;/code&gt; exit status. In all other cases the pipeline execution is terminated. &lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Nextflow provides a very flexible mechanism for defining the job resource request and handling error events. It makes it possible to automatically reschedule failing tasks under certain conditions and to define job resource requests in a dynamic manner so that they can be adapted to the actual job&apos;s needs and to optimize the overall resource utilisation. &lt;/p&gt;
	</description>
    </item>
    <item>
      <title>Developing a bioinformatics pipeline across multiple environments</title>
      <link>http://www.nextflow.io//blog/2016/developing-bioinformatics-pipeline-across-multiple-environments.html</link>
      <pubDate>Thu, 4 Feb 2016 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2016/developing-bioinformatics-pipeline-across-multiple-environments.html</guid>
      	<description>
	&lt;p&gt;As a new bioinformatics student with little formal computer science training, there are few things that scare me more than PhD committee meetings and having to run my code in a completely different operating environment. &lt;/p&gt;&lt;p&gt;Recently my work landed me in the middle of the phylogenetic tree jungle and the computational requirements of my project far outgrew the resources that were available on our institute’s &lt;a href=&quot;https://en.wikipedia.org/wiki/Univa_Grid_Engine&quot;&gt;Univa Grid Engine&lt;/a&gt; based cluster. Luckily for me, an opportunity arose to participate in a joint program at the MareNostrum HPC at the &lt;a href=&quot;http://www.bsc.es&quot;&gt;Barcelona Supercomputing Centre&lt;/a&gt; (BSC).&lt;/p&gt;&lt;p&gt;As one of the top 100 supercomputers in the world, the &lt;a href=&quot;https://www.bsc.es/marenostrum-support-services&quot;&gt;MareNostrum III&lt;/a&gt; dwarfs our cluster and consists of nearly 50&apos;000 processors. However it soon became apparent that with great power comes great responsibility and in the case of the BSC, great restrictions. These include no internet access, restrictive wall times for jobs, longer queues, fewer pre-installed binaries and an older version of bash. Faced with the possibility of having to rewrite my 16 bodged scripts for another queuing system I turned to Nextflow.&lt;/p&gt;&lt;p&gt;Straight off the bat I was able to reduce all my previous scripts to a single Nextflow script. Admittedly, the original code was not great, but the data processing model made me feel confident in what I was doing and I was able to reduce the volume of code to 25% of its initial amount whilst making huge improvements in the readability. The real benefits however came from the portability.&lt;/p&gt;&lt;p&gt;I was able to write the project on my laptop (Macbook Air), continuously test it on my local desktop machine (Linux) and then perform more realistic heavy lifting runs on the cluster, all managed from a single GitHub repository. The BSC uses the &lt;a href=&quot;https://en.wikipedia.org/wiki/Platform_LSF&quot;&gt;Load Sharing Facility&lt;/a&gt; (LSF) platform with longer queue times, but a large number of CPUs. My project on the other hand had datasets that require over 100&apos;000 tasks, but the tasks processes themselves run for a matter of seconds or minutes. We were able to marry these two competing interests deploying Nextflow in a &lt;a href=&quot;/blog/2015/mpi-like-execution-with-nextflow.html&quot;&gt;distributed execution manner that resemble the one of an MPI application&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;In this configuration, the queuing system allocates the Nextflow requested resources and using the embedded &lt;a href=&quot;https://ignite.apache.org/&quot;&gt;Apache Ignite&lt;/a&gt; clustering engine, Nextflow handles the submission of processes to the individual nodes. &lt;/p&gt;&lt;p&gt;Here is some examples of how to run the same Nextflow project over multiple platforms.&lt;/p&gt;&lt;h4&gt;Local&lt;/h4&gt;&lt;p&gt;If I wished to launch a job locally I can run it with the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow run myproject.nf
&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;Univa Grid Engine (UGE)&lt;/h4&gt;&lt;p&gt;For the UGE I simply needed to specify the following in the &lt;code&gt;nextflow.config&lt;/code&gt; file: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;process {
        executor=&amp;#39;uge&amp;#39;
        queue=&amp;#39;my_queue&amp;#39;
}  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then launch the pipeline execution as we did before:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow run myproject.nf     
&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;Load Sharing Facility (LSF)&lt;/h4&gt;&lt;p&gt;For running the same pipeline in the MareNostrum HPC enviroment, taking advantage of the MPI standard to deploy my workload, I first created a wrapper script (for example &lt;code&gt;bsc-wrapper.sh&lt;/code&gt;) declaring the resources that I want to reserve for the pipeline execution:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
#BSUB -oo logs/output_%J.out
#BSUB -eo logs/output_%J.err
#BSUB -J myProject
#BSUB -q bsc_ls
#BSUB -W 2:00
#BSUB -x
#BSUB -n 512
#BSUB -R &amp;quot;span[ptile=16]&amp;quot;
export NXF_CLUSTER_SEED=$(shuf -i 0-16777216 -n 1)
mpirun --pernode bin/nextflow run concMSA.nf -with-mpi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then can execute it using &lt;code&gt;bsub&lt;/code&gt; as shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bsub &amp;lt; bsc-wrapper.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;By running Nextflow in this way and given the wrapper above, a single &lt;code&gt;bsub&lt;/code&gt; job will run on 512 cores in 32 computing nodes (512/16 = 32) with a maximum wall time of 2 hours. Thousands of Nextflow processes can be spawned during this and the execution can be monitored in the standard manner from a single Nextflow output and error files. If any errors occur the execution can of course to continued with &lt;a href=&quot;/docs/latest/getstarted.html?highlight=resume#modify-and-resume&quot;&gt;&lt;code&gt;-resume&lt;/code&gt; command line option&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;Conclusion&lt;/h3&gt;&lt;p&gt;Nextflow provides a simplified way to develop across multiple platforms and removes much of the overhead associated with running niche, user developed pipelines in an HPC environment. &lt;/p&gt;
	</description>
    </item>
    <item>
      <title>MPI-like distributed execution with Nextflow</title>
      <link>http://www.nextflow.io//blog/2015/mpi-like-execution-with-nextflow.html</link>
      <pubDate>Fri, 13 Nov 2015 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2015/mpi-like-execution-with-nextflow.html</guid>
      	<description>
	&lt;p&gt;The main goal of Nextflow is to make workflows portable across different computing platforms taking advantage of the parallelisation features provided by the underlying system without having to reimplement your application code. &lt;/p&gt;&lt;p&gt;From the beginning Nextflow has included executors designed to target the most popular resource managers and batch schedulers commonly used in HPC data centers, such as &lt;a href=&quot;http://www.univa.com&quot;&gt;Univa Grid Engine&lt;/a&gt;, &lt;a href=&quot;http://www.ibm.com/systems/platformcomputing/products/lsf/&quot;&gt;Platform LSF&lt;/a&gt;, &lt;a href=&quot;https://computing.llnl.gov/linux/slurm/&quot;&gt;SLURM&lt;/a&gt;, &lt;a href=&quot;http://www.pbsworks.com/Product.aspx?id=1&quot;&gt;PBS&lt;/a&gt; and &lt;a href=&quot;http://www.adaptivecomputing.com/products/open-source/torque/&quot;&gt;Torque&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;When using one of these executors Nextflow submits the computational workflow tasks as independent job requests to the underlying platform scheduler, specifying for each of them the computing resources needed to carry out its job. &lt;/p&gt;&lt;p&gt;This approach works well for workflows that are composed of long running tasks, which is the case of most common genomic pipelines.&lt;/p&gt;&lt;p&gt;However this approach does not scale well for workloads made up of a large number of short-lived tasks (e.g. a few seconds or sub-seconds). In this scenario the resource manager scheduling time is much longer than the actual task execution time, thus resulting in an overall execution time that is much longer than the real execution time. In some cases this represents an unacceptable waste of computing resources. &lt;/p&gt;&lt;p&gt;Moreover supercomputers, such as &lt;a href=&quot;https://www.bsc.es/marenostrum-support-services/mn3&quot;&gt;MareNostrum&lt;/a&gt; in the &lt;a href=&quot;https://www.bsc.es/&quot;&gt;Barcelona Supercomputer Center (BSC)&lt;/a&gt;, are optimized for memory distributed applications. In this context it is needed to allocate a certain amount of computing resources in advance to run the application in a distributed manner, commonly using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Message_Passing_Interface&quot;&gt;MPI&lt;/a&gt; standard.&lt;/p&gt;&lt;p&gt;In this scenario, the Nextflow execution model was far from optimal, if not unfeasible. &lt;/p&gt;&lt;h3&gt;Distributed execution&lt;/h3&gt;&lt;p&gt;For this reason, since the release 0.16.0, Nextflow has implemented a new distributed execution model that greatly improves the computation capability of the framework. It uses &lt;a href=&quot;https://ignite.apache.org/&quot;&gt;Apache Ignite&lt;/a&gt;, a lightweight clustering engine and in-memory data grid, which has been recently open sourced under the Apache software foundation umbrella. &lt;/p&gt;&lt;p&gt;When using this feature a Nextflow application is launched as if it were an MPI application. It uses a job wrapper that submits a single request specifying all the needed computing resources. The Nextflow command line is executed by using the &lt;code&gt;mpirun&lt;/code&gt; utility, as shown in the example below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
#$ -l virtual_free=120G
#$ -q &amp;lt;queue name&amp;gt;
#$ -N &amp;lt;job name&amp;gt;
#$ -pe ompi &amp;lt;nodes&amp;gt;
mpirun --pernode nextflow run &amp;lt;your-project-name&amp;gt; -with-mpi [pipeline parameters]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This tool spawns a Nextflow instance in each of the computing nodes allocated by the cluster manager. &lt;/p&gt;&lt;p&gt;Each Nextflow instance automatically connects with the other peers creating an &lt;em&gt;private&lt;/em&gt; internal cluster, thanks to the Apache Ignite clustering feature that is embedded within Nextflow itself. &lt;/p&gt;&lt;p&gt;The first node becomes the application driver that manages the execution of the workflow application, submitting the tasks to the remaining nodes that act as workers. &lt;/p&gt;&lt;p&gt;When the application is complete, the Nextflow driver automatically shuts down the Nextflow/Ignite cluster and terminates the job execution. &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;/img/nextflow-distributed-execution.png&quot; alt=&quot;Nextflow distributed execution&quot;&quot;/&gt;&lt;/p&gt;&lt;h3&gt;Conclusion&lt;/h3&gt;&lt;p&gt;In this way it is possible to deploy a Nextflow workload in a supercomputer using an execution strategy that resembles the MPI distributed execution model. This doesn&apos;t require to implement your application using the MPI api/library and it allows you to maintain your code portable across different execution platforms. &lt;/p&gt;&lt;p&gt;Although we do not currently have a performance comparison between a Nextflow distributed execution and an equivalent MPI application, we assume that the latter provides better performance due to its low-level optimisation. &lt;/p&gt;&lt;p&gt;Nextflow, however, focuses on the fast prototyping of scientific applications in a portable manner while maintaining the ability to scale and distribute the application workload in an efficient manner in an HPC cluster. &lt;/p&gt;&lt;p&gt;This allows researchers to validate an experiment, quickly, reusing existing tools and software components. This eventually makes it possible to implement an optimised version using a low-level programming language in the second stage of a project. &lt;/p&gt;&lt;p&gt;Read the documentation to learn more about the &lt;a href=&quot;http://www.nextflow.io/docs/latest/ignite.html#execution-with-mpi&quot;&gt;Nextflow distributed execution model&lt;/a&gt;.&lt;/p&gt;
	</description>
    </item>
    <item>
      <title>The impact of Docker containers on the performance of genomic pipelines</title>
      <link>http://www.nextflow.io//blog/2015/the-impact-of-docker-on-genomic-pipelines.html</link>
      <pubDate>Mon, 15 Jun 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/the-impact-of-docker-on-genomic-pipelines.html</guid>
      	<description>
	&lt;p&gt;In a recent publication we assessed the impact of Docker containers technology on the performance of bioinformatic tools and data analysis workflows. &lt;/p&gt;&lt;p&gt;We benchmarked three different data analyses: a RNA sequence pipeline for gene expression, a consensus assembly and variant calling pipeline, and finally a pipeline for the detection and mapping of long non-coding RNAs. &lt;/p&gt;&lt;p&gt;We found that Docker containers have only a minor impact on the performance of common genomic data analysis, which is negligible when the executed tasks are demanding in terms of computational time.&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://peerj.com/preprints/1171/&quot;&gt;This publication is available as PeerJ preprint at this link&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
	</description>
    </item>
    <item>
      <title>Innovation In Science - The story behind Nextflow</title>
      <link>http://www.nextflow.io//blog/2015/innovation-in-science-the-story-behind-nextflow.html</link>
      <pubDate>Tue, 9 Jun 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/innovation-in-science-the-story-behind-nextflow.html</guid>
      	<description>
	&lt;p&gt;Innovation can be viewed as the application of solutions that meet new requirements or existing market needs. Academia has traditionally been the driving force of innovation. Scientific ideas have shaped the world, but only a few of them were brought to market by the inventing scientists themselves, resulting in both time and financial loses. &lt;/p&gt;&lt;p&gt;Lately there have been several attempts to boost scientific innovation and translation, with most notable in Europe being the Horizon 2020 funding program. The problem with these types of funding is that they are not designed for PhDs and Postdocs, but rather aim to promote the collaboration of senior scientists in different institutions. This neglects two very important facts, first and foremost that most of the Nobel prizes were given for discoveries made when scientists were in their 20&apos;s / 30&apos;s (not in their 50&apos;s / 60&apos;s). Secondly, innovation really happens when a few individuals (not institutions) face a problem in their everyday life/work, and one day they just decide to do something about it (end-user innovation). Without realizing, these people address a need that many others have. They don’t do it for the money or the glory; they do it because it bothers them! Many examples of companies that started exactly this way include Apple, Google, and Virgin Airlines.&lt;/p&gt;&lt;h3&gt;The story of Nextflow&lt;/h3&gt;&lt;p&gt;Similarly, Nextflow started as an attempt to solve the every-day computational problems we were facing with “big biomedical data” analyses. We wished that our huge and almost cryptic BASH-based pipelines could handle parallelization automatically. In our effort to make that happen we stumbled upon the &lt;a href=&quot;http://en.wikipedia.org/wiki/Dataflow_programming&quot;&gt;Dataflow&lt;/a&gt; programming model and Nextflow was created. We were getting furious every time our two-week long pipelines were crashing and we had to re-execute them from the beginning. We, therefore, developed a caching system, which allows Nextflow to resume any pipeline from the last executed step. While we were really enjoying developing a new &lt;a href=&quot;http://en.wikipedia.org/wiki/Domain-specific_language&quot;&gt;DSL&lt;/a&gt; and creating our own operators, at the same time we were not willing to give up our favorite Perl/Python scripts and one-liners, and thus Nextflow became a polyglot. &lt;/p&gt;&lt;p&gt;Another problem we were facing was that our pipelines were invoking a lot of third-party software, making distribution and execution on different platforms a nightmare. Once again while searching for a solution to this problem, we were able to identify a breakthrough technology &lt;a href=&quot;https://www.docker.com/&quot;&gt;Docker&lt;/a&gt;, which is now revolutionising cloud computation. Nextflow has been one of the first framework, that fully supports Docker containers and allows pipeline execution in an isolated and easy to distribute manner. Of course, sharing our pipelines with our friends rapidly became a necessity and so we had to make Nextflow smart enough to support &lt;a href=&quot;https://github.com&quot;&gt;Github&lt;/a&gt; and &lt;a href=&quot;https://bitbucket.org/&quot;&gt;Bitbucket&lt;/a&gt; integration.&lt;/p&gt;&lt;p&gt;I don’t know if Nextflow will make as much difference in the world as the Dataflow programming model and Docker container technology are making, but it has already made a big difference in our lives and that is all we ever wanted… &lt;/p&gt;&lt;h3&gt;Conclusion&lt;/h3&gt;&lt;p&gt;Summarising, it is a pity that PhDs and Postdocs are the neglected engine of Innovation. They are not empowered to innovate, by identifying and addressing their needs, and to potentially set up commercial solutions to their problems. This fact becomes even sadder when you think that only 3% of Postdocs have a chance to become PIs in the UK. Instead more and more money is being invested into the senior scientists who only require their PhD students and Postdocs to put another step into a well-defined ladder. In todays world it seems that ideas, such as Nextflow, will only get funded for their scientific value, not as innovative concepts trying to address a need.&lt;/p&gt;
	</description>
    </item>
    <item>
      <title>Introducing Nextflow REPL Console</title>
      <link>http://www.nextflow.io//blog/2015/introducing-nextflow-console.html</link>
      <pubDate>Tue, 14 Apr 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/introducing-nextflow-console.html</guid>
      	<description>
	&lt;p&gt;The latest version of Nextflow introduces a new &lt;em&gt;console&lt;/em&gt; graphical interface. &lt;/p&gt;&lt;p&gt;The Nextflow console is a REPL (&lt;a href=&quot;http://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop&quot;&gt;read-eval-print loop&lt;/a&gt;) environment that allows one to quickly test part of a script or pieces of Nextflow code in an interactive manner. &lt;/p&gt;&lt;p&gt;It is a handy tool that allows one to evaluate fragments of Nextflow/Groovy code or fast prototype a complete pipeline script. &lt;/p&gt;&lt;h3&gt;Getting started&lt;/h3&gt;&lt;p&gt;The console application is included in the latest version of Nextflow (&lt;a href=&quot;https://github.com/nextflow-io/nextflow/releases&quot;&gt;0.13.1&lt;/a&gt; or higher). &lt;/p&gt;&lt;p&gt;You can try this feature out, having Nextflow installed on your computer, by entering the following command in your shell terminal: &lt;code&gt;nextflow console&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;When you execute it for the first time, Nextflow will spend a few seconds downloading the required runtime dependencies. When complete the console window will appear as shown in the picture below. &lt;/p&gt;&lt;p&gt;&lt;img src=&apos;/img/nextflow-console1.png&apos; alt=&quot;Nextflow console&quot; style=&apos;width: 100%; padding: 2em 1em;&apos; /&gt;&lt;/p&gt;&lt;p&gt;It contains a text editor (the top white box) that allows you to enter and modify code snippets. The results area (the bottom yellow box) will show the executed code&apos;s output. &lt;/p&gt;&lt;p&gt;At the top you will find the menu bar (not shown in this picture) and the actions toolbar that allows you to open, save, execute (etc.) the code been tested.&lt;/p&gt;&lt;p&gt;As a practical execution example, simply copy and paste the following piece of code in the console editor box:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;echo true 

process sayHello {

 &amp;quot;&amp;quot;&amp;quot;
 echo Hello world
 &amp;quot;&amp;quot;&amp;quot; 

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then, in order to evaluate it, open the &lt;code&gt;Script&lt;/code&gt; menu in the top menu bar and select the &lt;code&gt;Run&lt;/code&gt; command. Alternatively you can use the &lt;code&gt;CTRL+R&lt;/code&gt; keyboard shortcut to run it (&lt;code&gt;⌘+R&lt;/code&gt; on the Mac). In the result box an output similar to the following will appear: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[warm up] executor &amp;gt; local
[00/d78a0f] Submitted process &amp;gt; sayHello (1)
Hello world
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now you can try to modify the entered process script, execute it again and check that the printed result has changed. &lt;/p&gt;&lt;p&gt;If the output doesn&apos;t appear, open the &lt;code&gt;View&lt;/code&gt; menu and make sure that the entry &lt;code&gt;Capture Standard
Output&lt;/code&gt; is selected (it must have a tick on the left).&lt;/p&gt;&lt;p&gt;It is worth noting that the global script context is maintained across script executions. This means that variables declared in the global script scope are not lost when the script run is complete, and they can be accessed in further executions of the same or another piece of code.&lt;/p&gt;&lt;p&gt;In order to reset the global context you can use the command &lt;code&gt;Clear Script Context&lt;/code&gt; available in the &lt;code&gt;Script&lt;/code&gt; menu. &lt;/p&gt;&lt;h3&gt;Conclusion&lt;/h3&gt;&lt;p&gt;The Nextflow console is a REPL environment which allows you to experiment and get used to the Nextflow programming environment. By using it you can prototype or test your code without the need to create/edit script files.&lt;/p&gt;&lt;p&gt;Note: the Nextflow console is implemented by sub-classing the &lt;a href=&quot;http://groovy-lang.org/groovyconsole.html&quot;&gt;Groovy console&lt;/a&gt; tool. For this reason you may find some labels that refer to the Groovy programming environment in this program. &lt;/p&gt;
	</description>
    </item>
    <item>
      <title>Using Docker for scientific data analysis in an HPC cluster   </title>
      <link>http://www.nextflow.io//blog/2014/using-docker-in-hpc-cluster.html</link>
      <pubDate>Thu, 6 Nov 2014 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2014/using-docker-in-hpc-cluster.html</guid>
      	<description>
	&lt;p&gt;Scientific data analysis pipelines are rarely composed by a single piece of software. In a real world scenario, computational pipelines are made up of multiple stages, each of which can execute many different scripts, system commands and external tools deployed in a hosting computing environment, usually an HPC cluster. &lt;/p&gt;&lt;p&gt;As I work as a research engineer in a bioinformatics lab I experience on a daily basis the difficulties related on keeping such a piece of software consistent. &lt;/p&gt;&lt;p&gt;Computing enviroments can change frequently in order to test new pieces of software or maybe because system libraries need to be updated. For this reason replicating the results of a data analysis over time can be a challenging task. &lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://www.docker.com&quot;&gt;Docker&lt;/a&gt; has emerged recently as a new type of virtualisation technology that allows one to create a self-contained runtime environment. There are plenty of examples showing the benefits of using it to run application services, like web servers or databases. &lt;/p&gt;&lt;p&gt;However it seems that few people have considered using Docker for the deployment of scientific data analysis pipelines on distributed cluster of computer, in order to simplify the development, the deployment and the replicability of this kind of applications. &lt;/p&gt;&lt;p&gt;For this reason I wanted to test the capabilities of Docker to solve these problems in the cluster available in our &lt;a href=&quot;http://www.crg.eu&quot;&gt;institute&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;Method&lt;/h2&gt;&lt;p&gt;The Docker engine has been installed in each node of our cluster, that runs a &lt;a href=&quot;http://www.univa.com/products/grid-engine.php&quot;&gt;Univa grid engine&lt;/a&gt; resource manager. A Docker private registry instance has also been installed in our internal network, so that images can be pulled from the local repository in a much faster way when compared to the public &lt;a href=&quot;http://registry.hub.docker.com&quot;&gt;Docker registry&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Moreover the Univa grid engine has been configured with a custom &lt;a href=&quot;http://www.gridengine.eu/mangridengine/htmlman5/complex.html&quot;&gt;complex&lt;/a&gt; resource type. This allows us to request a specific Docker image as a resource type while submitting a job execution to the cluster. &lt;/p&gt;&lt;p&gt;The Docker image is requested as a &lt;em&gt;soft&lt;/em&gt; resource, by doing that the UGE scheduler tries to run a job to a node where that image has already been pulled, otherwise a lower priority is given to it and it is executed, eventually, by a node where the specified Docker image is not available. This will force the node to pull the required image from the local registry at the time of the job execution. &lt;/p&gt;&lt;p&gt;This environment has been tested with &lt;a href=&quot;https://github.com/cbcrg/piper-nf&quot;&gt;Piper-NF&lt;/a&gt;, a genomic pipeline for the detection and mapping of long non-coding RNAs. &lt;/p&gt;&lt;p&gt;The pipeline runs on top of Nextflow, which takes care of the tasks parallelisation and submits the jobs for execution to the Univa grid engine. &lt;/p&gt;&lt;p&gt;The Piper-NF code wasn&apos;t modified in order to run it using Docker. Nextflow is able to handle it automatically. The Docker containers are run in such a way that the tasks result files are created in the hosting file system, in other words it behaves in a completely transparent manner without requiring extra steps or affecting the flow of the pipeline execution. &lt;/p&gt;&lt;p&gt;It was only necessary to specify the Docker image (or images) to be used in the Nextflow configuration file for the pipeline. You can read more about this at &lt;a href=&quot;http://www.nextflow.io/docs/latest/docker.html&quot;&gt;this link&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;Results&lt;/h2&gt;&lt;p&gt;To benchmark the impact of Docker on the pipeline performance a comparison was made running it with and without Docker.&lt;/p&gt;&lt;p&gt;For this experiment 10 cluster nodes were used. The pipeline execution launches around 100 jobs, and it was run 5 times by using the same dataset with and without Docker. &lt;/p&gt;&lt;p&gt;The average execution time without Docker was 28.6 minutes, while the average pipeline execution time, running each job in a Docker container, was 32.2 minutes. Thus, by using Docker the overall execution time increased by something around 12.5%. &lt;/p&gt;&lt;p&gt;It is important to note that this time includes both the Docker bootstrap time, and the time overhead that is added to the task execution by the virtualisation layer. &lt;/p&gt;&lt;p&gt;For this reason the actual task run time was measured as well i.e. without including the Docker bootstrap time overhead. In this case, the aggregate average task execution time was 57.3 minutes and 59.5 minutes when running the same tasks using Docker. Thus, the time overhead added by the Docker virtualisation layer to the effective task run time can be estimated to around 4% in our test.&lt;/p&gt;&lt;p&gt;Keeping the complete toolset required by the pipeline execution within a Docker image dramatically reduced configuration and deployment problems. Also storing these images into the private and &lt;a href=&quot;https://registry.hub.docker.com/repos/cbcrg/&quot;&gt;public&lt;/a&gt; repositories with a unique tag allowed us to replicate the results without the usual burden required to set-up an identical computing environment. &lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;The fast start-up time for Docker containers technology allows one to virtualise a single process or the execution of a bunch of applications, instead of a complete operating system. This opens up new possibilities, for example the possibility to &quot;virtualise&quot; distributed job executions in an HPC cluster of computers. &lt;/p&gt;&lt;p&gt;The minimal performance loss introduced by the Docker engine is offset by the advantages of running your analysis in a self-contained and dead easy to reproduce runtime environment, which guarantees the consistency of the results over time and across different computing platforms. &lt;/p&gt;&lt;h4&gt;Credits&lt;/h4&gt;&lt;p&gt;Thanks to Arnau Bria and the all scientific systems admins team to manage the Docker installation in the CRG computing cluster. &lt;/p&gt;
	</description>
    </item>
    <item>
      <title>Reproducibility in Science - Nextflow meets Docker </title>
      <link>http://www.nextflow.io//blog/2014/nextflow-meets-docker.html</link>
      <pubDate>Tue, 9 Sep 2014 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2014/nextflow-meets-docker.html</guid>
      	<description>
	&lt;p&gt;The scientific world nowadays operates on the basis of published articles. These are used to report novel discoveries to the rest of the scientific community. &lt;/p&gt;&lt;p&gt;But have you ever wondered what a scientific article is? It is a:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;defeasible argument for claims, supported by&lt;/li&gt;
  &lt;li&gt;exhibited, reproducible data and methods, and&lt;/li&gt;
  &lt;li&gt;explicit references to other work in that domain;&lt;/li&gt;
  &lt;li&gt;described using domain-agreed technical terminology,&lt;/li&gt;
  &lt;li&gt;which exists within a complex ecosystem of technologies, people and activities.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Hence the very essence of Science relies on the ability of scientists to reproduce and build upon each other’s published results.&lt;/p&gt;&lt;p&gt;So how much can we rely on published data? In a recent report in Nature, researchers at the Amgen corporation found that only 11% of the academic research in the literature was reproducible by their groups [&lt;a href=&quot;http://www.nature.com/nature/journal/v483/n7391/full/483531a.html&quot;&gt;1&lt;/a&gt;]. &lt;/p&gt;&lt;p&gt;While many factors are likely at play here, perhaps the most basic requirement for reproducibility holds that the materials reported in a study can be uniquely identified and obtained, such that experiments can be reproduced as faithfully as possible. This information is meant to be documented in the &quot;materials and methods&quot; of journal articles, but as many can attest, the information provided there is often not adequate for this task. &lt;/p&gt;&lt;h3&gt;Promoting Computational Research Reproducibility&lt;/h3&gt;&lt;p&gt;Encouragingly scientific reproducibility has been at the forefront of many news stories and there exist numerous initiatives to help address this problem. Particularly, when it comes to producing reproducible computational analyses, some publications are starting to publish the code and data used for analysing and generating figures. &lt;/p&gt;&lt;p&gt;For example, many articles in Nature and in the new Elife journal (and others) provide a &quot;source data&quot; download link next to figures. Sometimes Elife might even have an option to download the source code for figures.&lt;/p&gt;&lt;p&gt;As pointed out by Melissa Gymrek &lt;a href=&quot;http://melissagymrek.com/science/2014/08/29/docker-reproducible-research.html&quot;&gt;in a recent post&lt;/a&gt; this is a great start, but there are still lots of problems. She wrote that, for example, if one wants to re-execute a data analyses from these papers, he/she will have to download the scripts and the data, to only realize that he/she has not all the required libraries, or that it only runs on, for example, an Ubuntu version he/she doesn&apos;t have, or some paths are hard-coded to match the authors&apos; machine. &lt;/p&gt;&lt;p&gt;If it&apos;s not easy to run and doesn&apos;t run out of the box the chances that a researcher will actually ever run most of these scripts is close to zero, especially if they lack the time or expertise to manage the required installation of third-party libraries, tools or implement from scratch state-of-the-art data processing algorithms.&lt;/p&gt;&lt;h3&gt;Here comes Docker&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.docker.com&quot;&gt;Docker&lt;/a&gt; containers technology is a solution to many of the computational research reproducibility problems. Basically, it is a kind of a lightweight virtual machine where you can set up a computing environment including all the libraries, code and data that you need, within a single &lt;em&gt;image&lt;/em&gt;. &lt;/p&gt;&lt;p&gt;This image can be distributed publicly and can seamlessly run on any major Linux operating system. No need for the user to mess with installation, paths, etc. &lt;/p&gt;&lt;p&gt;They just run the Docker image you provided, and everything is set up to work out of the box. Researchers have already started discussing this (e.g. &lt;a href=&quot;http://www.bioinformaticszen.com/post/reproducible-assembler-benchmarks/&quot;&gt;here&lt;/a&gt;, and &lt;a href=&quot;https://bcbio.wordpress.com/2014/03/06/improving-reproducibility-and-installation-of-genomic-analysis-pipelines-with-docker/&quot;&gt;here&lt;/a&gt;).&lt;/p&gt;&lt;h3&gt;Docker and Nextflow: a perfect match&lt;/h3&gt;&lt;p&gt;One big advantage Docker has compared to &lt;em&gt;traditional&lt;/em&gt; machine virtualisation technology is that it doesn&apos;t need a complete copy of the operating system, thus it has a minimal startup time. This makes it possible to virtualise single applications or launch the execution of multiple containers, that can run in parallel, in order to speedup a large computation. &lt;/p&gt;&lt;p&gt;Nextflow is a data-driven toolkit for computational pipelines, which aims to simplify the deployment of distributed and highly parallelised pipelines for scientific applications. &lt;/p&gt;&lt;p&gt;The latest version integrates the support for Docker containers that enables the deployment of self-contained and truly reproducible pipelines. &lt;/p&gt;&lt;h3&gt;How they work together&lt;/h3&gt;&lt;p&gt;A Nextflow pipeline is made up by putting together several processes. Each process can be written in any scripting language that can be executed by the Linux platform (BASH, Perl, Ruby, Python, etc). Parallelisation is automatically managed by the framework and it is implicitly defined by the processes input and output declarations. &lt;/p&gt;&lt;p&gt;By integrating Docker with Nextflow, every pipeline process can be executed independently in its own container, this guarantees that each of them run in a predictable manner without worrying about the configuration of the target execution platform. Moreover the minimal overhead added by Docker allows us to spawn multiple container executions in a parallel manner with a negligible performance loss when compared to a platform &lt;em&gt;native&lt;/em&gt; execution. &lt;/p&gt;&lt;h3&gt;An example&lt;/h3&gt;&lt;p&gt;As a proof of concept of the Docker integration with Nextflow you can try out the pipeline example at this &lt;a href=&quot;https://github.com/nextflow-io/examples/blob/master/blast-parallel.nf&quot;&gt;link&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;It splits a protein sequences multi FASTA file into chunks of &lt;em&gt;n&lt;/em&gt; entries, executes a BLAST query for each of them, then extracts the top 10 matching sequences and finally aligns the results with the T-Coffee multiple sequence aligner. &lt;/p&gt;&lt;p&gt;In a common scenario you generally need to install and configure the tools required by this script: BLAST and T-Coffee. Moreover you should provide a formatted protein database in order to execute the BLAST search.&lt;/p&gt;&lt;p&gt;By using Docker with Nextflow you only need to have the Docker engine installed in your computer and a Java VM. In order to try this example out, follow these steps: &lt;/p&gt;&lt;p&gt;Install the latest version of Nextflow by entering the following command in your shell terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; curl -fsSL get.nextflow.io | bash
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then download the required Docker image with this command: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt; docker pull nextflow/examples
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can check the content of the image looking at the &lt;a href=&quot;https://github.com/nextflow-io/examples/blob/master/Dockerfile&quot;&gt;Dockerfile&lt;/a&gt; used to create it.&lt;/p&gt;&lt;p&gt;Now you are ready to run the demo by launching the pipeline execution as shown below: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow run examples/blast-parallel.nf -with-docker
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will run the pipeline printing the final alignment out on the terminal screen. You can also provide your own protein sequences multi FASTA file by adding, in the above command line, the option &lt;code&gt;--query &amp;lt;file&amp;gt;&lt;/code&gt; and change the splitting chunk size with &lt;code&gt;--chunk n&lt;/code&gt; option. &lt;/p&gt;&lt;p&gt;Note: the result doesn&apos;t have a real biological meaning since it uses a very small protein database. &lt;/p&gt;&lt;h3&gt;Conclusion&lt;/h3&gt;&lt;p&gt;The mix of Docker, GitHub and Nextflow technologies make it possible to deploy self-contained and truly replicable pipelines. It requires zero configuration and enables the reproducibility of data analysis pipelines in any system in which a Java VM and the Docker engine are available.&lt;/p&gt;&lt;h3&gt;Learn how to do it!&lt;/h3&gt;&lt;p&gt;Follow our documentation for a quick start using Docker with Nextflow at the following link &lt;a href=&quot;http://www.nextflow.io/docs/latest/docker.html&quot;&gt;http://www.nextflow.io/docs/latest/docker.html&lt;/a&gt;&lt;/p&gt;
	</description>
    </item>
    <item>
      <title>Share Nextflow pipelines with Github</title>
      <link>http://www.nextflow.io//blog/2014/share-nextflow-pipelines-with-github.html</link>
      <pubDate>Thu, 7 Aug 2014 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2014/share-nextflow-pipelines-with-github.html</guid>
      	<description>
	&lt;p&gt;The &lt;a href=&quot;https://github.com&quot;&gt;GitHub&lt;/a&gt; code repository and collaboration platform is widely used between researchers to publish their work and to collaborate on projects source code. &lt;/p&gt;&lt;p&gt;Even more interestingly a few months ago &lt;a href=&quot;https://github.com/blog/1840-improving-github-for-science&quot;&gt;GitHub announced improved support for researchers&lt;/a&gt; making it possible to get a Digital Object Identifier (DOI) for any GitHub repository archive. &lt;/p&gt;&lt;p&gt;With a DOI for your GitHub repository archive your code becomes formally citable in scientific publications.&lt;/p&gt;&lt;h3&gt;Why use GitHub with Nextflow?&lt;/h3&gt;&lt;p&gt;The latest Nextflow release (0.9.0) seamlessly integrates with GitHub. This feature allows you to manage your code in a more consistent manner, or use other people&apos;s Nextflow pipelines, published through GitHub, in a quick and transparent manner. &lt;/p&gt;&lt;h3&gt;How it works&lt;/h3&gt;&lt;p&gt;The idea is very simple, when you launch a script execution with Nextflow, it will look for a file with the pipeline name you&apos;ve specified. If that file does not exist, it will look for a public repository with the same name on GitHub. If it is found, the repository is automatically downloaded to your computer and the code executed. This repository is stored in the Nextflow home directory, by default &lt;code&gt;$HOME/.nextflow&lt;/code&gt;, thus it will be reused for any further execution.&lt;/p&gt;&lt;p&gt;You can try this feature out, having Nextflow (version 0.9.0 or higher) installed in your computer, by simply entering the following command in your shell terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow run nextflow-io/hello 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The first time you execute this command Nextflow will download the pipeline at the following GitHub repository &lt;code&gt;https://github.com/nextflow-io/hello&lt;/code&gt;, as you don&apos;t already have it in your computer. It will then execute it producing the expected output.&lt;/p&gt;&lt;p&gt;In order for a GitHub repository to be used as a Nextflow project, it must contain at least one file named &lt;code&gt;main.nf&lt;/code&gt; that defines your Nextflow pipeline script.&lt;/p&gt;&lt;h3&gt;Run a specific revision&lt;/h3&gt;&lt;p&gt;Any Git branch, tag or commit ID in the GitHub repository can be used to specify a revision, that you want to execute, when running your pipeline by adding the &lt;code&gt;-r&lt;/code&gt; option to the run command line. So for example you could enter:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow run nextflow-io/hello -r mybranch   
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;or &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow run nextflow-io/hello -r v1.1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This can be very useful when comparing different versions of your project. It also guarantees consistent results in your pipeline as your source code evolves.&lt;/p&gt;&lt;h3&gt;Commands to manage pipelines&lt;/h3&gt;&lt;p&gt;The following commands allows you to perform some basic operations that can be used to manage your pipelines. Anyway Nextflow is not meant to replace functionalities provided by the &lt;a href=&quot;http://git-scm.com/&quot;&gt;Git&lt;/a&gt; tool, you may still need it to create new repositories or commit changes, etc. &lt;/p&gt;&lt;h4&gt;List available pipelines&lt;/h4&gt;&lt;p&gt;The &lt;code&gt;ls&lt;/code&gt; command allows you to list all the pipelines you have downloaded in your computer. For example: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow ls
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This prints a list similar to the following one: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cbcrg/piper-nf
nextflow-io/hello
&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;Show pipeline information&lt;/h4&gt;&lt;p&gt;By using the &lt;code&gt;info&lt;/code&gt; command you can show information from a downloaded pipeline. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ nextflow info hello
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This command prints: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt; repo name  : nextflow-io/hello
 home page  : http://github.com/nextflow-io/hello
 local path : $HOME/.nextflow/assets/nextflow-io/hello
 main script: main.nf
 revisions  : 
 * master (default)
   mybranch
   v1.1 [t]
   v1.2 [t]   
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Starting from the top it shows: 1) the repository name; 2) the project home page; 3) the local folder where the pipeline has been downloaded; 4) the script that is executed when launched; 5) the list of available revisions i.e. branches + tags. Tags are marked with a &lt;code&gt;[t]&lt;/code&gt; on the right, the current checked-out revision is marked with a &lt;code&gt;*&lt;/code&gt; on the left.&lt;/p&gt;&lt;h4&gt;Pull or update a pipeline&lt;/h4&gt;&lt;p&gt;The &lt;code&gt;pull&lt;/code&gt; command allows you to download a pipeline from a GitHub repository or to update it if that repository has already been downloaded. For example: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow pull nextflow-io/examples
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Downloaded pipelines are stored in the folder &lt;code&gt;$HOME/.nextflow/assets&lt;/code&gt; in your computer.&lt;/p&gt;&lt;h4&gt;Clone a pipeline into a folder&lt;/h4&gt;&lt;p&gt;The &lt;code&gt;clone&lt;/code&gt; command allows you to copy a Nextflow pipeline project to a directory of your choice. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow clone nextflow-io/hello target-dir 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If the destination directory is omitted the specified pipeline is cloned to a directory with the same name as the pipeline &lt;em&gt;base&lt;/em&gt; name (e.g. &lt;code&gt;hello&lt;/code&gt;) in the current folder. &lt;/p&gt;&lt;p&gt;The clone command can be used to inspect or modify the source code of a pipeline. You can eventually commit and push back your changes by using the usual Git/GitHub workflow. &lt;/p&gt;&lt;h4&gt;Drop an installed pipeline&lt;/h4&gt;&lt;p&gt;Downloaded pipelines can be deleted by using the &lt;code&gt;drop&lt;/code&gt; command, as shown below: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow drop nextflow-io/hello
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Limitations and known problems&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;s&gt;GitHub private repositories currently are not supported&lt;/s&gt; Support for private GitHub repositories has been introduced with version 0.10.0.&lt;/li&gt;
  &lt;li&gt;&lt;s&gt;Symlinks committed in a Git repository are not resolved correctly  when downloaded/cloned by Nextflow&lt;/s&gt; Symlinks are resolved correctly when using Nextflow version 0.11.0 (or higher).&lt;/li&gt;
&lt;/ul&gt;
	</description>
    </item>

  </channel> 
</rss>
