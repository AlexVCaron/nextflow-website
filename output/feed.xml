<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nextflow Blog</title>
    <link>http://www.nextflow.io/</link>
    <atom:link href="http://www.nextflow.io//feed.xml" rel="self" type="application/rss+xml" />
    <description>Blogging about Nextflow, computational pipelines and parallel programming</description>
    <language>en-gb</language>
    <pubDate>Tue, 9 Sep 2014 19:52:38 +0200</pubDate>
    <lastBuildDate>Tue, 9 Sep 2014 19:52:38 +0200</lastBuildDate>

    <item>
      <title>Reproducibility in Science - Nextflow meets Docker </title>
      <link>http://www.nextflow.io//blog/2014/nextflow-meets-docker.html</link>
      <pubDate>Tue, 9 Sep 2014 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2014/nextflow-meets-docker.html</guid>
      	<description>
	&lt;p&gt;The scientific world nowadays operates on the basis of published articles. These are used to report novel discoveries to the rest of the scientific community. &lt;/p&gt;&lt;p&gt;But have you ever wondered what a scientific article is? It is a:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;defeasible argument for claims, supported by&lt;/li&gt;
  &lt;li&gt;exhibited, reproducible data and methods, and&lt;/li&gt;
  &lt;li&gt;explicit references to other work in that domain;&lt;/li&gt;
  &lt;li&gt;described using domain-agreed technical terminology,&lt;/li&gt;
  &lt;li&gt;which exists within a complex ecosystem of technologies, people and activities.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Hence the very essence of Science relies on the ability of scientists to reproduce and build upon each otherâ€™s published results.&lt;/p&gt;&lt;p&gt;So how much can we rely on published data? In a recent report in Nature, researchers at the Amgen corporation found that only 11% of the academic research in the literature was reproducible by their groups [&lt;a href=&quot;http://www.nature.com/nature/journal/v483/n7391/full/483531a.html&quot;&gt;1&lt;/a&gt;]. &lt;/p&gt;&lt;p&gt;While many factors are likely at play here, perhaps the most basic requirement for reproducibility holds that the materials reported in a study can be uniquely identified and obtained, such that experiments can be reproduced as faithfully as possible. This information is meant to be documented in the &quot;materials and methods&quot; of journal articles, but as many can attest, the information provided there is often not adequate for this task. &lt;/p&gt;&lt;h3&gt;Promoting Computational Research Reproducibility&lt;/h3&gt;&lt;p&gt;Encouragingly scientific reproducibility has been at the forefront of many news stories and there exist numerous initiatives to help address this problem. Particularly, when it comes to producing reproducible computational analyses, some publications are starting to publish the code and data used for analysing and generating figures. &lt;/p&gt;&lt;p&gt;For example, many articles in Nature and in the new Elife journal (and others) provide a &quot;source data&quot; download link next to figures. Sometimes Elife might even have an option to download the source code for figures.&lt;/p&gt;&lt;p&gt;This is a good start, but there are still lots of problems. For example, if one wants to re-execute a data analyses from these papers, he/she will have to download the scripts and the data, to only realize that he/she has not all the required libraries, or that it only runs on, for example, an Ubuntu version he/she doesn&apos;t have, or some paths are hard-coded to match the authors&apos; machines. &lt;/p&gt;&lt;p&gt;If it&apos;s not easy to run and doesn&apos;t run out of the box the chances that a researcher will actually ever run most of these scripts is close to zero, especially if they lack the time or expertise to manage the required installation of third-party libraries, tools or implement from scratch state-of-the-art data processing algorithms.&lt;/p&gt;&lt;h3&gt;Here it comes Docker&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.docker.com&quot;&gt;Docker&lt;/a&gt; containers technology is a solution to many of the computational research reproducibility problems. Basically, it is kind of a lightweight virtual machine where you can set up a computing environment including all the libraries, code and data that you need, into a single &lt;em&gt;image&lt;/em&gt;. &lt;/p&gt;&lt;p&gt;This image can be distributed publicly and can seamlessly run on any major Linux operating system. No need for the user to mess with installation, paths, etc. &lt;/p&gt;&lt;p&gt;They just run the Docker image you provided, and everything is set up to work out of the box. Researchers have already started discussing this (e.g. &lt;a href=&quot;http://www.bioinformaticszen.com/post/reproducible-assembler-benchmarks/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://bcbio.wordpress.com/2014/03/06/improving-reproducibility-and-installation-of-genomic-analysis-pipelines-with-docker/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://melissagymrek.com/science/2014/08/29/docker-reproducible-research.html&quot;&gt;here&lt;/a&gt;).&lt;/p&gt;&lt;h3&gt;Docker and Nextflow: a perfect match&lt;/h3&gt;&lt;p&gt;A big advantage of Docker containers compared to &lt;em&gt;traditional&lt;/em&gt; machine virtualisation technology is that it doesn&apos;t need a complete copy of the operating system, thus it has a minimal startup time. This makes it possible to virtualise single applications or to launch the execution of plenty of containers, that can run in parallel, in order to speedup a large computation. &lt;/p&gt;&lt;p&gt;Nextflow is a data-driven toolkit for computational pipelines, which aims to simplify the deployment of distributed and highly parallelised pipelines for scientific applications. &lt;/p&gt;&lt;p&gt;The latest version integrates the support for Docker containers that enables the deployment of self-contained and truly reproducible pipelines. &lt;/p&gt;&lt;h3&gt;How they work together&lt;/h3&gt;&lt;p&gt;A Nextflow pipeline is made up by putting together several processes. Each process can be written in any scripting language that can be executed by the Linux platform (BASH, Perl, Ruby, Python, etc). Parallelisation is automatically managed by the framework and it is implicitly defined by the processes input and output declarations. &lt;/p&gt;&lt;p&gt;By integrating Docker with Nextflow, every pipeline process can be executed independently in its own container, this guarantee that each of them run in a predictable manner without worrying about the configuration of the target execution platform. Moreover the minimal overhead added by Docker allow us to spawn multiple containers executions in a parallel manner with a negligible performance loss when compared to a platform &lt;em&gt;native&lt;/em&gt; execution. &lt;/p&gt;&lt;h3&gt;An example&lt;/h3&gt;&lt;p&gt;As a proof of concept of the Docker integration with Nextflow you can try out the pipeline example at this &lt;a href=&quot;https://github.com/nextflow-io/examples/blob/master/blast-parallel.nf&quot;&gt;link&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;It splits a protein sequences&apos; FASTA file in chunks of &lt;em&gt;n&lt;/em&gt; entries, executes a BLAST query for each of them, then extracts the top 10 matching sequences and finally aligns the results with the T-Coffee multiple sequence aligner. &lt;/p&gt;&lt;p&gt;In a common scenario you would need to install and configure the tools required by this script: BLAST and T-Coffee. Moreover you should provide a formatted protein database in order to execute the BLAST search.&lt;/p&gt;&lt;p&gt;By using Docker with Nextflow you only need to have the Docker engine installed in your computer and a Java VM. In order to try this example out follow these steps: &lt;/p&gt;&lt;p&gt;Install the latest version of Nextflow by entering the following command in your shell terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; curl -fsSL get.nextflow.io | bash
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then download the required Docker image with this command: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt; docker pull nextflow/examples
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can check the content of the image looking at the &lt;a href=&quot;https://github.com/nextflow-io/examples/blob/master/Dockerfile&quot;&gt;Dockerfile&lt;/a&gt; used to create it.&lt;/p&gt;&lt;p&gt;Now you are ready to run the demo by launching the pipeline execution as shown below: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow run examples/blast-parallel.nf -with-docker
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will run the pipeline printing the final alignment out in the terminal screen. You can also provide your own protein sequences&apos; FASTA file by adding, in the above command line, the option &lt;code&gt;--query &amp;lt;file&amp;gt;&lt;/code&gt; and change the splitting chunk size with &lt;code&gt;--chunk n&lt;/code&gt; option. &lt;/p&gt;&lt;p&gt;Note: the result doesn&apos;t have a real biological meaning since it uses a very small protein database. &lt;/p&gt;&lt;h3&gt;Conclusion&lt;/h3&gt;&lt;p&gt;The mix of Docker, GitHub and Nextflow technologies makes it possible to deploy self-contained and truly replicable pipelines. It requires zero configuration and enables the reproducibility of data analysis pipelines in any system in which a Java VM and the Docker engine are available.&lt;/p&gt;&lt;h3&gt;Learn how to do it!&lt;/h3&gt;&lt;p&gt;Follow our documentation for a quick start using Docker with Nextflow at the following link &lt;a href=&quot;http://www.nextflow.io/docs/latest/docker.html&quot;&gt;http://www.nextflow.io/docs/latest/docker.html&lt;/a&gt;&lt;/p&gt;
	</description>
    </item>
    <item>
      <title>Share Nextflow pipelines with Github</title>
      <link>http://www.nextflow.io//blog/2014/share-nextflow-pipelines-with-github.html</link>
      <pubDate>Thu, 7 Aug 2014 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2014/share-nextflow-pipelines-with-github.html</guid>
      	<description>
	&lt;p&gt;The &lt;a href=&quot;https://github.com&quot;&gt;GitHub&lt;/a&gt; code repository and collaboration platform is widely used between researchers to publish their work and to collaborate on projects source code. &lt;/p&gt;&lt;p&gt;Even more interestingly a few months ago &lt;a href=&quot;https://github.com/blog/1840-improving-github-for-science&quot;&gt;GitHub announced improved support for researchers&lt;/a&gt; making it possible to get a Digital Object Identifier (DOI) for any GitHub repository archive. &lt;/p&gt;&lt;p&gt;With a DOI for your GitHub repository archive your code becomes formally citable in scientific publications.&lt;/p&gt;&lt;h3&gt;Why use GitHub with Nextflow?&lt;/h3&gt;&lt;p&gt;The latest Nextflow release (0.9.0) seamlessly integrates with GitHub. This feature allows you to manage your code in a more consistent manner, or use other people&apos;s Nextflow pipelines, published through GitHub, in a quick and transparent manner. &lt;/p&gt;&lt;h3&gt;How it works&lt;/h3&gt;&lt;p&gt;The idea is very simple, when you launch a script execution with Nextflow, it will look for a file with the pipeline name you&apos;ve specified. If that file does not exist, it will look for a public repository with the same name on GitHub. If it is found, the repository is automatically downloaded to your computer and the code executed. This repository is stored in the Nextflow home directory, by default &lt;code&gt;$HOME/.nextflow&lt;/code&gt;, thus it will be reused for any further execution.&lt;/p&gt;&lt;p&gt;You can try this feature out, having Nextflow (version 0.9.0 or higher) installed in your computer, by simply entering the following command in your shell terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow run nextflow-io/hello 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The first time you execute this command Nextflow will download the pipeline at the following GitHub repository &lt;code&gt;https://github.com/nextflow-io/hello&lt;/code&gt;, as you don&apos;t already have it in your computer. It will then execute it producing the expected output.&lt;/p&gt;&lt;p&gt;In order for a GitHub repository to be used as a Nextflow project, it must contain at least one file named &lt;code&gt;main.nf&lt;/code&gt; that defines your Nextflow pipeline script.&lt;/p&gt;&lt;h3&gt;Run a specific revision&lt;/h3&gt;&lt;p&gt;Any Git branch, tag or commit ID in the GitHub repository can be used to specify a revision, that you want to execute, when running your pipeline by adding the &lt;code&gt;-r&lt;/code&gt; option to the run command line. So for example you could enter:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow run nextflow-io-/hello -r mybranch   
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;or &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow run nextflow-io-/hello -r v1.1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This can be very useful when comparing different versions of your project. It also guarantees consistent results in your pipeline as your source code evolves.&lt;/p&gt;&lt;h3&gt;Commands to manage pipelines&lt;/h3&gt;&lt;p&gt;The following commands allows you to perform some basic operations that can be used to manage your pipelines. Anyway Nextflow is not meant to replace functionalities provided by the &lt;a href=&quot;http://git-scm.com/&quot;&gt;Git&lt;/a&gt; tool, you may still need it to create new repositories or commit changes, etc. &lt;/p&gt;&lt;h4&gt;List available pipelines&lt;/h4&gt;&lt;p&gt;The &lt;code&gt;ls&lt;/code&gt; command allows you to list all the pipelines you have downloaded in your computer. For example: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow ls
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This prints a list similar to the following one: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cbcrg/piper-nf
nextflow-io/hello
&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;Show pipeline information&lt;/h4&gt;&lt;p&gt;By using the &lt;code&gt;info&lt;/code&gt; command you can show information from a downloaded pipeline. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ nextflow info hello
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This command prints: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt; repo name  : nextflow-io/hello
 home page  : http://github.com/nextflow-io/hello
 local path : $HOME/.nextflow/assets/nextflow-io/hello
 main script: main.nf
 revisions  : 
 * master (default)
   mybranch
   v1.1 [t]
   v1.2 [t]   
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Starting from the top it shows: 1) the repository name; 2) the project home page; 3) the local folder where the pipeline has been downloaded; 4) the script that is executed when launched; 5) the list of available revisions i.e. branches + tags. Tags are marked with a &lt;code&gt;[t]&lt;/code&gt; on the right, the current checked-out revision is marked with a &lt;code&gt;*&lt;/code&gt; on the left.&lt;/p&gt;&lt;h4&gt;Pull or update a pipeline&lt;/h4&gt;&lt;p&gt;The &lt;code&gt;pull&lt;/code&gt; command allows you to download a pipeline from a GitHub repository or to update it if that repository has already been downloaded. For example: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow pull nextflow-io/examples
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Downloaded pipelines are stored in the folder &lt;code&gt;$HOME/.nextflow/assets&lt;/code&gt; in your computer.&lt;/p&gt;&lt;h4&gt;Clone a pipeline into a folder&lt;/h4&gt;&lt;p&gt;The &lt;code&gt;clone&lt;/code&gt; command allows you to copy a Nextflow pipeline project to a directory of your choice. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow clone nextflow-io/hello target-dir 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If the destination directory is omitted the specified pipeline is cloned to a directory with the same name as the pipeline &lt;em&gt;base&lt;/em&gt; name (e.g. &lt;code&gt;hello&lt;/code&gt;) in the current folder. &lt;/p&gt;&lt;p&gt;The clone command can be used to inspect or modify the source code of a pipeline. You can eventually commit and push back your changes by using the usual Git/GitHub workflow. &lt;/p&gt;&lt;h4&gt;Drop an installed pipeline&lt;/h4&gt;&lt;p&gt;Downloaded pipelines can be deleted by using the &lt;code&gt;drop&lt;/code&gt; command, as shown below: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nextflow drop nextflow-io/hello
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Limitations and known problems&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;s&gt;GitHub private repositories currently are not supported&lt;/s&gt; Support for private GitHub repositories has been introduced with version 0.10.0.&lt;/li&gt;
  &lt;li&gt;Symlinks committed in a Git repository are not resolved correctly  when downloaded/cloned by Nextflow&lt;/li&gt;
&lt;/ul&gt;
	</description>
    </item>

  </channel> 
</rss>
